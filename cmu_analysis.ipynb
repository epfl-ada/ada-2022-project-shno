{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a304467-db1f-4da5-b212-f253e59c4466",
   "metadata": {},
   "source": [
    "# Applied Data Analysis - Milestone P2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec5a34-8773-47c2-a18a-f4cfa15c173a",
   "metadata": {},
   "source": [
    "## Title : Hollywood's social structure\n",
    "\n",
    "### Group Name : SHNO\n",
    "\n",
    "### Project pipeline\n",
    "\n",
    "- [Libraries](#Libraries)\n",
    "- [CMU Data importation](#Data-Importation)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "    - [Movie metadata](#Movie-metadata)\n",
    "    - [Character metadata](#Character-metadata)\n",
    "    - [Plot summaries](#Plot-summaries)\n",
    "    - [TV Tropes](#TV-Tropes)\n",
    "- [IMDb Datasets Exploratory Data Analysis](#IMDb-Datasets-Analysis)\n",
    "    - [title.akas.tsv.gz](#title.akas.tsv.gz)\n",
    "    - [title.basics.tsv.gz](#title.basics.tsv.gz)\n",
    "    - [title.crew.tsv.gz](#title.crew.tsv.gz)\n",
    "    - [title.episode.tsv.gz](#title.episode.tsv.gz)\n",
    "    - [title.principals.tsv.gz](#title.principals.tsv.gz)\n",
    "    - [title.ratings.tsv.gz](#title.ratings.tsv.gz)\n",
    "    - [name.basics.tsv.gz](#name.basics.tsv.gz)\n",
    "- [Data pre-processing, transformation and merging](#Methods)\n",
    "    - [Data pre-processing and transformation](#Methods)\n",
    "    - [IMDb Dataset merging](#Methods)\n",
    "        - [Outlier and missing value correction using IMDb datset values](#Outlier-and-missing-value-correction)\n",
    "        - [Dataset Expansion with IMDb datsets merging](#IMDb-datset-merging)\n",
    "    - [Build initial co-stardom graphs](#Methods)\n",
    "        - [Actor-to-actor](#Methods)\n",
    "        - [Movie-to-movie](#Methods)\n",
    "- [Methods](#Methods)\n",
    "    - [Step 1](#Step1)\n",
    "    - [Step 2](#Step2)\n",
    "    - [Step 3](#Step3)\n",
    "    - [Step 4](#Step4)\n",
    "    - [Step 5](#Step5)\n",
    "    - [Step 6](#Step6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df7d98-f9a3-40f0-a1a3-38417f1d193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install library used to perform sentiment analysis\n",
    "# !pip install vaderSentiment\n",
    "# interactive graph visualization\n",
    "# !pip install pyvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a4eff6-2c97-4d98-9866-299c04a53149",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f57797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# sentiment analysis\n",
    "# import vaderSentiment\n",
    "\n",
    "# graphs handling\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set pandas options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ed001-afbf-4e0b-aeda-2e606a9e989b",
   "metadata": {},
   "source": [
    "## CMU Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data paths\n",
    "DATA_FOLDER = 'data/MovieSummaries/'\n",
    "\n",
    "CHARACTER_META = DATA_FOLDER+'character.metadata.tsv'\n",
    "MOVIE_META = DATA_FOLDER+'movie.metadata.tsv'\n",
    "NAME_CLUSTERS = DATA_FOLDER+'name.clusters.txt'\n",
    "PLOT_SUMM = DATA_FOLDER+'plot_summaries.txt'\n",
    "TV_TROPES = DATA_FOLDER+'tvtropes.clusters.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies metadata\n",
    "movie_meta = pd.read_csv(MOVIE_META, sep='\\t', header=None)\n",
    "\n",
    "movie_meta.columns = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue',\n",
    "                     'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "# load characters metadata\n",
    "character_meta = pd.read_csv(CHARACTER_META, sep='\\t', header=None)\n",
    "character_meta.columns = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date' ,'character_name', 'actor_date_of_birth', 'actor_gender',\n",
    "                    'actor_height_m', 'actor_ethnicity_id', 'actor_name', 'actor_age_at_movie_release', 'freebase_character/actor_map_id',\n",
    "                    'freebase_character_id', 'freebase_actor_id']\n",
    "\n",
    "# load charcter name clusters\n",
    "name_clusters = pd.read_csv(NAME_CLUSTERS, sep='\\t', header=None)\n",
    "name_clusters.columns = ['character_name', 'freebase_character/actor_map_id']\n",
    "\n",
    "# load plot summaries\n",
    "plot_summ = pd.read_csv(PLOT_SUMM, sep='\\t', header=None)\n",
    "plot_summ.columns = ['wikipedia_movie_id', 'summary']\n",
    "\n",
    "# load tv tropes\n",
    "tv_tropes = pd.read_csv(TV_TROPES, sep='\\t', header=None)\n",
    "tv_tropes.columns = ['character_type', 'freebase_character/actor_map_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176ae61",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe1833",
   "metadata": {},
   "source": [
    "### CMU Datasets\n",
    "\n",
    "The data is separated in n different files namely **plot_summaries**, **movie.metadata**, **character.metadata**, **tvtropes.clusters** and **name.clusters**. We will explore the files individually before merging the relevant features on two different dataframes : the first will be movie-centric indexed by movie_id, the second will be cast centered and indexed by the actor_id. This manipulation will ease the construction of graphs involving movie to movie, actor to movie, actor to movie graphs on which we will perform an extensive network analysis.\n",
    "\n",
    "#### Movie metadata\n",
    "\n",
    "The movie metadata file is extracted in a dataframe with the following attributes :  \n",
    "\n",
    "`wikipedia_movie_id`:  wikidata movie id  (str)  \n",
    "`freebase_movie_id`:  freebase movie id  (str)  \n",
    "`movie_name`:  movie name ()  \n",
    "`release_date`:  unformated release date of the movie  ()    \n",
    "`movie_revenue`:  box office revenue ()  \n",
    "`runtime`:   movie runtime ()  \n",
    "`languages`:  movie languages (freebase id name tuples)  \n",
    "`countries`:  movie countries release (freebase id name tuples)  \n",
    "`genres`:  movie genres (freebase id name tuples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedfeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_meta.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20a510-f911-4e7b-a149-0c07f89a3543",
   "metadata": {},
   "source": [
    "We compute the ratio of missing values per attribute to see which feature are usable or not for our analysis. We can see that almost 90% of the movie revenue attribute is missing, therefore we will drop this column (maybe try to fill this attribute with IMDb datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88721613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display null values for every column\n",
    "(movie_meta.isna().sum()/len(movie_meta))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c319a00-af7c-4f10-90df-9e195bfd2d5d",
   "metadata": {},
   "source": [
    "The next lines prove us that the wikipedia_movie_id and freebase_movie_id can both be used as an index, and that this dataframe contains no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of movies (distinct IDs)\n",
    "n_wiki_movies = movie_meta['wikipedia_movie_id'].nunique()\n",
    "n_freebase_id = movie_meta['freebase_movie_id'].nunique()\n",
    "\n",
    "assert(len(movie_meta) == n_wiki_movies)\n",
    "assert(n_wiki_movies == n_freebase_id)\n",
    "\n",
    "print(f'There are {n_wiki_movies} movies in the CMU database')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16d29c-5cb1-4aae-a893-0d1f4dea2d96",
   "metadata": {},
   "source": [
    "We then need to convert to format the release date attribute into a dedicated datetime object to ease future computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5531848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert dates into date format\n",
    "movie_meta['movie_release_date_formatted'] = pd.to_datetime(movie_meta['movie_release_date'], errors='coerce').apply(lambda x: x.date())\n",
    "movie_meta.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c4a89-f0db-4ac2-8b39-ada1292e597f",
   "metadata": {},
   "source": [
    "We have to check the instances where the movie year is invalid, and then manually correct it if possible. We are lucky, there is only one instance of such case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd454a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display instances in which movie year is invalid\n",
    "movie_meta[movie_meta['movie_release_date_formatted'].isnull() & ~(movie_meta['movie_release_date'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct invalid release dates\n",
    "movie_meta.loc[movie_meta['wikipedia_movie_id'] == 29666067, 'movie_release_date_formatted'] = date(2010, 12, 2)\n",
    "assert 0 == len(movie_meta[movie_meta['movie_release_date_formatted'].isnull() & ~(movie_meta['movie_release_date'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3732cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# corrected data\n",
    "movie_meta[movie_meta['wikipedia_movie_id'] == 29666067]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update original column\n",
    "movie_meta['movie_release_date'] = movie_meta['movie_release_date_formatted']\n",
    "del movie_meta['movie_release_date_formatted']\n",
    "# save year\n",
    "movie_meta['movie_release_year'] = movie_meta['movie_release_date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = int(movie_meta['movie_release_year'].dropna().max() - movie_meta['movie_release_year'].dropna().min())\n",
    "movie_meta['movie_release_year'].plot.hist(bins=n_bins)\n",
    "\n",
    "plt.xlabel('Movie Release Year')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.title('Evolution of yearly movie releases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(movie_meta['movie_box_office_revenue']).plot.hist(bins=100)\n",
    "\n",
    "plt.xlabel('Movie Box Office Revenue (log)')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.title('Movie Box office revenue distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of movie runtime\n",
    "movie_meta['movie_runtime'].plot.box()\n",
    "\n",
    "plt.ylabel('Movie Runtime')\n",
    "plt.title('Movie Box office revenue distribution')\n",
    "plt.show()\n",
    "movie_meta['movie_runtime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81da84c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display outliers\n",
    "movie_meta.sort_values(by='movie_runtime', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa51cf9",
   "metadata": {},
   "source": [
    "To fix outliers and missing values, we plan to use the imdb dataset to find if we can extract the values from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b71f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of movie runtime\n",
    "# We display values between 0.05 and 0.95 quantiles as we will fix the outliers with the imdb dataset\n",
    "display_range = (movie_meta['movie_runtime'].quantile(0.05), movie_meta['movie_runtime'].quantile(0.95))\n",
    "movie_meta['movie_runtime'].plot.hist(bins=50, range=display_range)\n",
    "\n",
    "plt.xlabel('Movie Runtime')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.title('Movie runtime distribution between 0.05 and 0.95 quantiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta = movie_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042517ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta.loc[:, 'movie_languages_ids'] = test_meta['movie_languages'].apply(lambda x: ast.literal_eval(x).values())\n",
    "test_meta.loc[:, 'movie_countries_ids'] = test_meta['movie_countries'].apply(lambda x: ast.literal_eval(x).values())\n",
    "test_meta.loc[:, 'movie_genres_ids'] = test_meta['movie_genres'].apply(lambda x: ast.literal_eval(x).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd184f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_ids = pd.Series([language for languages in test_meta['movie_languages_ids'] for language in languages])\n",
    "language_counts = language_ids.value_counts()[:10]\n",
    "\n",
    "country_ids = pd.Series([country for countries in test_meta['movie_countries_ids'] for country in countries])\n",
    "country_counts = country_ids.value_counts()[:10]\n",
    "\n",
    "genre_ids = pd.Series([genre for genres in test_meta['movie_genres_ids'] for genre in genres])\n",
    "genre_counts = genre_ids.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(20, 25))\n",
    "ax1.bar(x=language_counts.index, height=language_counts.values)\n",
    "ax1.set_xlabel('Language')\n",
    "ax1.set_ylabel('Number of movies')\n",
    "ax1.set_title('The 10 most frequent languages')\n",
    "\n",
    "ax2.bar(x=country_counts.index, height=country_counts.values)\n",
    "ax2.set_xlabel('Country')\n",
    "ax2.set_ylabel('Number of movies')\n",
    "ax2.set_title('The 10 most frequent countries')\n",
    "\n",
    "ax3.bar(x=genre_counts.index, height=genre_counts.values)\n",
    "ax3.set_xlabel('Genre')\n",
    "ax3.set_ylabel('Number of movies')\n",
    "ax3.set_title('The 10 most frequent genres')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992d199-51cf-4082-abcb-3e28984ce143",
   "metadata": {},
   "source": [
    "#### Plot summaries\n",
    "\n",
    "The plot summary file is extracted in a dataframe with the following attributes :\n",
    "\n",
    "`wikipedia_movie_id`:  wikidata movie id  (str)    \n",
    "`plot_summary`:  wikidata plot summary of the movie  (str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summ.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16fa7f3-e94a-4068-b2e5-a957a19811d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trivial tokenizer\n",
    "plot_summ['count'] = plot_summ['summary'].apply(lambda x: len(x.split()))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "plot_summ['count'].plot(kind='hist', ax = axes[0], bins=50)\n",
    "plot_summ['count'].plot(kind='hist', logy=True, bins=50, ax=axes[1])\n",
    "#plt.suptitle('Plot summary word count distribution', x=0.5, y=1.05, ha='center', fontsize='xx-large')\n",
    "axes[0].title.set_text('Word count distribution')\n",
    "axes[1].title.set_text('Log scaled word count distribution')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07aa0c-6653-4c88-a861-b6abc0f8562e",
   "metadata": {},
   "source": [
    "We can merge the two previous datasets namely containing namely plot_summary and movie_metadata information into a single dataframe. Unfortunately, the plot_summary dataframe contains the summary of 42303 movies far from the 81741 movies described in the movie_metadata dataframe. The intersection of the dataframes on movie_id yields 42204 collisions, meaning that 99 summaries were not matched with a movie. We will thus keep it as a separate dataframe in case we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934c91d-fb4a-4ae5-a4e2-0f93fe4bf606",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(movie_meta, plot_summ, left_on='wikipedia_movie_id', right_on='wikipedia_movie_id')\n",
    "\n",
    "merged.index = merged.wikipedia_movie_id\n",
    "merged = merged.drop(columns=['wikipedia_movie_id']).sort_values(by='wikipedia_movie_id')\n",
    "merged.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ecb83-48cb-4719-a16a-713f6f038d59",
   "metadata": {},
   "source": [
    "#### Character \n",
    "\n",
    "The character metadata file is extracted in a dataframe with the following attributes :\n",
    "\n",
    "`wikipedia_movie_id`:  wikidata movie id  ()  \n",
    "`freebase_movie_id`:  freebase movie id  ()  \n",
    "`release_date`:  unformated release date of the movie  ()   \n",
    "`character_name`:  character name  ()  \n",
    "`actor_date_of_birth`:  actor date of birth ()  \n",
    "`actor_gender`:  actor gender (str)  \n",
    "`actor_height`:  actor height ()  \n",
    "`actor_ethnicity`: actor ethnicity specified with a freebase id   \n",
    "`actor_name`:  actor name  ()  \n",
    "`actor_age_movie_release`:  actor age at movie release date ()  \n",
    "`freebase_character_to_actor`:   mapping from character freebase id to actor id ()  \n",
    "`freebase_character_id`:  character freebase id ()  \n",
    "`freebase_actor_id`:  actor freebase id ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72435272",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f757ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_meta['actor_gender'].value_counts().plot.bar()\n",
    "plt.xlabel('Actor gender')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.title('Actor genders in movies')\n",
    "plt.show()\n",
    "character_meta['actor_ethnicity_id'].value_counts()[:10].plot.bar()\n",
    "plt.xlabel('Actor ethnicity')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.title('Actor ethnicities in movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_meta['actor_age_at_movie_release'].hist(bins=101, range=(0, 100))\n",
    "plt.xlabel('actor age at movie release')\n",
    "plt.ylabel('Number of characters')\n",
    "plt.title('Distribution of actor age at movie release')\n",
    "plt.show()\n",
    "character_meta['actor_height_m'].hist(bins=25, range=(1.2, 2.2))\n",
    "plt.xlabel('actor height (m)')\n",
    "plt.ylabel('Number of characters')\n",
    "plt.title('Distribution of actor height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc725c5a-b4fe-4116-9bf5-830a602ad4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_clusters.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96621fc7-6966-4c6c-959b-9a232c923714",
   "metadata": {},
   "source": [
    "#### TV Tropes\n",
    "\n",
    "The tv tropes file is extracted in a dataframe with the following attributes :\n",
    "\n",
    "`character_type`:  short description of the character type (str)    \n",
    "`freebase_character/actor_map_id`:  dictionnary containing character name, movie name, actor name and actor map id  (dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_tropes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_tropes.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762dd84-2fe2-40df-98c5-26062ae07f63",
   "metadata": {},
   "source": [
    "As stated in the paper presenting the CMU datasets, there are 72 character/tv tropes types.  \n",
    "Our next task is to combine the last three datasets into a single dataframe that will contain character/actor information : we can make use of the 'id' attribute inside the 'freebase_character/actor_map_id' column to merge this dataframe with the character dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d80740-913d-4cfc-bc85-e1b87393558a",
   "metadata": {},
   "source": [
    "Our ultimate goal is to create two dataframes : the first will be movie-centric that is indexed by the (wikipedia_id/freebase_id) and will contain cast information in the form of a list/dictionnary, the second will actor-centric that is indexed by the actor id (freebase_id) and will contain all the actor information, characters played and adjacent actors (ids of the actors they collaborated with)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1265a9f",
   "metadata": {},
   "source": [
    "## IMDb Datasets Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204d9df",
   "metadata": {},
   "source": [
    "### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ae3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/imdb/'\n",
    "\n",
    "TITLES_AKA = DATA_FOLDER+'title.akas.tsv.gz'\n",
    "TITLES_BASICS = DATA_FOLDER+'title.basics.tsv.gz'\n",
    "TITLES_CREW = DATA_FOLDER+'title.crew.tsv.gz'\n",
    "TITLES_PRINCIPLES = DATA_FOLDER+'title.principals.tsv.gz'\n",
    "NAME_BASICS = DATA_FOLDER+'name.basics.tsv.gz'\n",
    "WRITERS = DATA_FOLDER+\"writers_after2012.pkl.gz\"\n",
    "DIRECTORS = DATA_FOLDER+\"directors_after2012.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e825843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "titles_meta = pd.read_csv(TITLES_AKA, sep='\\t')\n",
    "titles_basics = pd.read_csv(TITLES_BASICS, sep='\\t')\n",
    "titles_crew = pd.read_csv(TITLES_CREW, sep='\\t')\n",
    "titles_principles = pd.read_csv(TITLES_PRINCIPLES, sep='\\t')\n",
    "name_basics = pd.read_csv(NAME_BASICS, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043d4d9",
   "metadata": {},
   "source": [
    "### Filtering and pre-processing the data\n",
    "\n",
    "#### Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we selected only movies after 2012, as we already have movies before 2012\n",
    "threshold_year = 2012\n",
    "\n",
    "# From the titles_aka, we only retain the titleId and region, for the original titles\n",
    "df_titles_aka = titles_meta[['titleId', 'ordering', 'title']][(titles_meta['isOriginalTitle']==1)]\n",
    "\n",
    "# We retained only non-adult movies\n",
    "df_basics = titles_basics[(titles_basics['titleType'] == 'movie') & (titles_basics['isAdult'] == 0)]\n",
    "df_basics = df_basics.drop(['titleType', 'isAdult', 'endYear'], axis=1)\n",
    "df_basics = df_basics[df_basics['startYear'] != r\"\\N\"]\n",
    "df_basics['startYear'] = df_basics['startYear'].astype(int)\n",
    "\n",
    "after_treshold = list(df_basics['tconst'][df_basics['startYear'] >= threshold_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc65270",
   "metadata": {},
   "source": [
    "#### Writers and directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_writers_per_movie = titles_crew[['tconst', 'writers']]\n",
    "df_directors_per_movie = titles_crew[['tconst', 'directors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0632dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we selected only movies after the 2012, as we already have movies before 2012.\n",
    "# and took only movies with writers/directors\n",
    "df_writers_per_movie = df_writers_per_movie[(df_writers_per_movie['tconst'].isin(after_treshold)) &\n",
    "                                           (df_writers_per_movie['writers'] != r\"\\N\")]\n",
    "df_directors_per_movie = df_directors_per_movie[(df_directors_per_movie['tconst'].isin(after_treshold)) &\n",
    "                                               (df_directors_per_movie['directors'] != r\"\\N\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going from movie's id with their writers/directors, to writers/directors with the movies they wrote/directed\n",
    "\n",
    "df_writers_per_movie = df_writers_per_movie.assign(writers=df_writers_per_movie.writers.str.split(\",\"))\n",
    "df_writers_per_movie = df_writers_per_movie.writers.apply(pd.Series) \\\n",
    "    .merge(df_writers_per_movie, right_index=True, left_index=True) \\\n",
    "    .drop([\"writers\"], axis=1) \\\n",
    "    .melt(id_vars=['tconst'], value_name=\"writers\") \\\n",
    "    .drop(\"variable\", axis=1) \\\n",
    "    .dropna()\n",
    "df_writers_per_movie = df_writers_per_movie.groupby('writers')['tconst'].apply(list).to_frame()\n",
    "\n",
    "df_directors_per_movie = df_directors_per_movie.assign(directors=df_directors_per_movie.directors.str.split(\",\"))\n",
    "df_directors_per_movie = df_directors_per_movie.directors.apply(pd.Series) \\\n",
    "    .merge(df_directors_per_movie, right_index=True, left_index=True) \\\n",
    "    .drop([\"directors\"], axis=1) \\\n",
    "    .melt(id_vars=['tconst'], value_name=\"directors\") \\\n",
    "    .drop(\"variable\", axis=1) \\\n",
    "    .dropna()\n",
    "df_directors_per_movie = df_directors_per_movie.groupby('directors')['tconst'].apply(list).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling the final dataframes\n",
    "df_writers_per_movie.to_pickle(WRITERS)\n",
    "df_directors_per_movie.to_pickle(DIRECTORS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b163f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_writers = pd.read_pickle(WRITERS) \n",
    "df_directors = pd.read_pickle(DIRECTORS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b7cc2c",
   "metadata": {},
   "source": [
    "#### Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = titles_principles[(titles_principles['category'].str.contains('actor')) & \n",
    "                 (titles_principles['tconst'].isin(after_treshold))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_principles[(titles_principles['category'] != 'actor') &\n",
    "                 (titles_principles['category'] != 'director') &\n",
    "                 (titles_principles['category'] != 'writer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ca9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actors with the list of movies they played in\n",
    "# Issue with this because some actors are also directors or writers, and in that case\n",
    "# we will not count all the movies they were in\n",
    "df_actors = titles_principles[['tconst', 'nconst']][((titles_principles['category']=='actor') | \n",
    "                                                    (titles_principles['category']=='actress')) &\n",
    "                                                   (titles_principles['tconst'].isin(after_treshold))]\n",
    "\n",
    "df_actors = df_actors.assign(nconst=df_actors.nconst.str.split(\",\"))\n",
    "df_actors = df_actors.nconst.apply(pd.Series) \\\n",
    "    .merge(df_actors, right_index=True, left_index=True) \\\n",
    "    .drop([\"nconst\"], axis=1) \\\n",
    "    .melt(id_vars=['tconst'], value_name=\"nconst\") \\\n",
    "    .drop(\"variable\", axis=1) \\\n",
    "    .dropna()\n",
    "df_actors = df_actors.groupby('nconst')['tconst'].apply(list).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5350692",
   "metadata": {},
   "source": [
    "#### Crew information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b243d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basics.index = name_basics['nconst']\n",
    "df_name = name_basics.drop(['nconst', 'knownForTitles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging ids with actual crew information\n",
    "\n",
    "df_actors_info = df_actors.merge(df_name, how='inner', right_index=True, left_index=True)\n",
    "df_writers_info = df_writers.merge(df_name, how='inner', right_index=True, left_index=True)\n",
    "df_directors_info = df_directors.merge(df_name, how='inner', right_index=True, left_index=True)\n",
    "\n",
    "df_actors_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing crew with no birthyear\n",
    "\n",
    "df_actors_info = df_actors_info[df_actors_info['birthYear'] == r\"\\N\"]\n",
    "df_writers_info = df_writers_info[df_writers_info['birthYear'] == r\"\\N\"]\n",
    "df_directors_info = df_directors_info[df_directors_info['birthYear'] == r\"\\N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating crew from name_basics (all the crew merged)\n",
    "# Known for section doesn't contain all the movies\n",
    "\n",
    "df_crew = name_basics[(name_basics['birthYear'] != r\"\\N\") & (name_basics['knownForTitles'] != r\"\\N\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef029bb4",
   "metadata": {},
   "source": [
    "### To DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire une analyse de donnée initiale\n",
    "\n",
    "# Si possible :\n",
    "\n",
    "# Process les actors : ok\n",
    "# Filtrer les films pour pouvoir merge\n",
    "# Filter et preprocess crew comme writers et directors - ok\n",
    "# Merge writers, directors et crew avec les autres crews members de CMU\n",
    "# Merge les films de CMU avec ceux la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85656ab6",
   "metadata": {},
   "source": [
    "### Crew initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc78621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crew date of birth distribution\n",
    "\n",
    "df_crew['birthYear'] = df_crew['birthYear'].astype(int)\n",
    "plt.hist(df_crew['birthYear'].values, \n",
    "         bins = 100, log=True)\n",
    "\n",
    "plt.xlabel('Year of birth')\n",
    "plt.ylabel('Number of actors')\n",
    "plt.title('Distribution of the year of birth for the crew, histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top10 actors that played in the most nb of movies\n",
    "\n",
    "df_actors['nb of movies'] = df_actors['tconst'].apply(lambda x : len(x)) \n",
    "df_top_actors = df_actors.sort_values(by='nb of movies', ascending=False).head(10)\n",
    "df_top_actors = df_top_actors.merge(df_name, how='inner', right_index=True, left_on='nconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a05bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_top_actors['primaryName'].values, df_top_actors['nb of movies'].values)\n",
    "\n",
    "plt.xlabel('Actor name')\n",
    "plt.ylabel('Number of films')\n",
    "plt.title('Top10 actors that played in the most movies')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acc2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top10 directors that directed in the most nb of movies\n",
    "\n",
    "df_directors['nb of movies'] = df_directors['tconst'].apply(lambda x : len(x)) \n",
    "df_top_directors = df_directors.sort_values(by='nb of movies', ascending=False).head(10)\n",
    "df_top_directors = df_top_directors.merge(df_name, how='inner', right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3469ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_top_directors['primaryName'].values, df_top_directors['nb of movies'].values)\n",
    "\n",
    "plt.xlabel('Director name')\n",
    "plt.ylabel('Number of films')\n",
    "plt.title('Top10 directors that directed the most number of movies')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of films in which actors played\n",
    "\n",
    "plt.hist(df_actors['nb of movies'].values, \n",
    "         bins = 150, log=True)\n",
    "\n",
    "plt.xlabel('Number of movies')\n",
    "plt.ylabel('Number of actors')\n",
    "plt.title('Distribution of number of movies actors played in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe710270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of movies directed for directors\n",
    "\n",
    "plt.hist(df_directors['nb of movies'].values, \n",
    "         bins = 100, log=True)\n",
    "\n",
    "plt.xlabel('Number of movies')\n",
    "plt.ylabel('Number of directors')\n",
    "plt.title('Distribution of number of movies directors directed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f721e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Writers\n",
    "\n",
    "# Director date of birth distribution \n",
    "# Top10 directors that directed the most nb of movies\n",
    "# Distribution of number of films directed for each director\n",
    "# Add the same plots, but make all the related ones in subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591f4b5",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Outlier and missing value correction using IMDb datset values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef569123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ba96b8",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "\n",
    "#### Movie metadata\n",
    "\n",
    "TODO : \\\n",
    "Preprocessing notes: \n",
    "- Replacing the index = movie id\n",
    "- formatting the dates attributes\n",
    "- dropping duplicates\n",
    "- treating the NaN values in movie revenue \n",
    "- treating Nan values in movie runtime\n",
    "- desearealize genres/country/languages attributes\n",
    "- treating empty value (\"{}\") in country attribute\n",
    "- normalizing the numeric values (only before performing PCA/Regression/Classification)\n",
    "\n",
    "#### Character metadata\n",
    "\n",
    "TODO : \\\n",
    "Preprocessing notes: \n",
    "- joining this character dataset with the previous dataframe on wikipedia movie id\n",
    "- formatting the dates\n",
    "- verify that the freebase id of the actor is unique so it can be used as an index for actors\n",
    "- merge actor and character dataframe\n",
    "- sentiment analysis on the m neighbours words surrounding the character name\n",
    "\n",
    "#### Plot summaries\n",
    "\n",
    "TODO : \\\n",
    "Preprocessing notes:\n",
    "- indexing using the movie id\n",
    "- nlp methods : using spaCy nlp framework\n",
    "  ** tokenize\n",
    "  ** parse \n",
    "  ** removing stop word\n",
    "  ** lemmatise \n",
    "  ** topic prediction using Empath library \n",
    "  ** sentiment analysis using Vader\n",
    "- joining this dataset with movie dataset\n",
    "- character encoding\n",
    "- remove wikipedia markup sign e.g {{hatnote}}\n",
    "\n",
    "#### TV Tropes\n",
    "\n",
    "TODO : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbfde2",
   "metadata": {},
   "source": [
    "### IMDb Datasets merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087581fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9426b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read imdb to fix data\n",
    "# imdb_title_basics = pd.read_csv(IMDB_TITLE_BASICS, sep='\\t')\n",
    "# imdb_title_basics.columns = ['imdb_' + cn for cn in imdb_title_basics.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4b898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # display null values\n",
    "# imdb_title_basics.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294405dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_meta_imdb_merged = movie_meta.merge(imdb_title_basics, how='left', left_on='movie_name', right_on='imdb_primaryTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ac3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_meta_imdb_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02047048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_title_basics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe6b0e",
   "metadata": {},
   "source": [
    "### Data Transformation : Build co-stardom graphs : actor-to-actor and movie-to-movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96552e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b162ea95",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191b2be",
   "metadata": {},
   "source": [
    "### Step 1 : Co-stardom graphs\n",
    "\n",
    "##### 1.A : **Actor-to-actor**\n",
    "The way we are going to explore the data of this CMU repo augmented by some potentially other datasets, is first of all through building a co-stardom network. A costardom network is essentially a collaboration graph of film actors. The nodes represent movie star actors and two nodes are linked if the two-stars have starred in the same movie. We can add a weight to the link, the weight being the number of times two actors have performed together. This would be our first actor-to-actor graph.\n",
    "\n",
    "##### 1.B : **Movie-to-movie**\n",
    "We can similarly construct a movie-to-movie graph which could reveal interesting insights. In such a graph, a node would be a movie and two nodes would be linked if they share some of the cast members. If we deem it necessary, we can consider only the \"important\" people of the cast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a69af7",
   "metadata": {},
   "source": [
    "### Step 2 : Simplify and filter out nodes that are not necessary\n",
    "\n",
    "##### 2.A Filter out the graph nodes below a certain degree and the graph edges below a certain weight\n",
    "\n",
    "\n",
    "##### 2.B Create networks for Hollywood, Bollywood, and other countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f10d32",
   "metadata": {},
   "source": [
    "### Step 3 : Network analysis\n",
    "\n",
    "##### 3.A : **Community detection**  \n",
    "A network is said to have community structure if the nodes of the network can be easily grouped into (potentially overlapping) sets of nodes such that each set of nodes is densely connected internally. In the particular case of non-overlapping community finding, this implies that the network divides naturally into groups of nodes with dense connections internally and sparser connections between groups. A known algorithm to give us insights on this problem is the Girvan-Newman algorithm : it detects communities by progressively removing edges from the original network. The connected components of the remaining network are the communities    \n",
    "\n",
    "##### 3.B: **Clustering based on actor attributes**  \n",
    "The idea would be to use an algorithm that regroup actors with similar features we extracted and engineered in the preprocessing part.\n",
    "The fact that actors have categorical features prevent us from using a K-means clustering as the Euclidean distance is not well\n",
    "defined for categorical features. For this issue, we might use K-modes that mixes the Hamming distance for categorical data and Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb20a4e",
   "metadata": {},
   "source": [
    "### Step 4 : Build an ego network graph between actors\n",
    "\n",
    "#### Ego network methematical description\n",
    "\n",
    "Ego networks are network graphs were each individual node is an \"ego\". They allow us to describe and index the variation among individuals in the way they are embedded in \"local\" social structures.\n",
    "\n",
    "Ego networks come with many definitions and related metrics (here the ones that are of interest to us): \n",
    "\n",
    "- Neighborhood is the collection of ego and all nodes/ties to whom ego has a connection at some path length (by neighborhood we usually imply path length of one). N-step neighborhood are neighborhoods up to path length N.\n",
    "- In neighborhood includes all the actors with ties directly to ego.\n",
    "- Out neighborhood includes all the actors with ties directed from ego\n",
    "\n",
    "- Average geodesic distance is the mean of the shortest path lengths among all connected pairs in the ego network.\n",
    "- Diameter of an ego network is the length of the longest path between connected actors\n",
    "- Brokerage is number of pairs not directly connected. Normalized brokerage is brokerage divided by number of pairs\n",
    "- Number of weak components, where a weak component is the biggest number of actors who are connected, not taking into account the direction of the ties.\n",
    "\n",
    "- Two-step reach gives the percentage of all actors in the network that are within two directed steps of ego.  \n",
    "- Reach efficiency is the two-step reach divided by its size.\n",
    "\n",
    "- Brokerage is the number of pairs not directly connected. And the normalized brokerage is the brokerage divided by the number of pairs.\n",
    "\n",
    "- Structural holes is the absence of ties between two parts of a network. They that help determine very important aspects of positional advantage/disadvantage of individuals that result from how they are embedded in neighborhoods. This helps to think about how and why the ways that an actor is connected affect its constraints and opportunities. \n",
    "\n",
    "#### Plan\n",
    "\n",
    "- Describe and index the variation among actors in the way they are embedded in « local » social structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eaeb59",
   "metadata": {},
   "source": [
    "### Step 5 : Compute and visualize network metrics to highlight the power and influence of individuals\n",
    "\n",
    "#### Metrics mathematical description\n",
    "\n",
    "Graph metrics can be divided into 3 categories, the ones related to Connections, Distributions and Segmentation.\n",
    "\n",
    "1) Connections\n",
    "\n",
    "- Assortativity is the extent to which actors form ties with similar versus dissimilar others. This factor of similarity can be gender, race, age, status or any other characteristic.\n",
    "\n",
    "- Multiplexity is a structural property of network ties that can give the existence of more than one type of relationship between two actors\n",
    "\n",
    "- Propinquity describes the tendency for actors to have more ties with other actors that are close geographically.\n",
    "\n",
    "2) Distributions\n",
    "\n",
    "- Centrality\n",
    "\n",
    "    - Betweenness centrality captures which nodes are important in the flow of the network. This by computing for every vertex the number of shortest paths that pass through it. The formula that computes it is the following :\n",
    "    \n",
    "    $$g(v)= \\sum_{s \\neq v \\neq t}\\frac{\\sigma_{st}(v)}{\\sigma_{st}}$$\n",
    "    \n",
    "        where sigma_{st} is the total number of shortest paths from node s to node t and sigma_{st}(v) is the number of those that pass through v.\n",
    "        \n",
    "    - Closeness centrality is the reciprocal of the sum of the length of the shortest paths between a given node and all other nodes in the graph. The more central a node is the closer it is to all other nodes.\n",
    "    \n",
    "    $$C_B(x)= \\frac{1}{\\sum_y d(y,x)}$$\n",
    "\n",
    "        where d(y,x) is the distance (length of the shortest path) between vertices x and y.\n",
    "        \n",
    "    - Degree centrality counts how many edges each node has, hence the most degree central actor is the one with the most ties.\n",
    "\n",
    "3) Segmentation\n",
    "\n",
    "- Clustering coefficient measures the degree to which nodes in a graph tend to cluster together.\n",
    "\n",
    "- Coehsion is the degree to which actors are connected directly to each other by cohesive bonds. Where cohesive bonds are bonds that link members of a social group to one another and to the group as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be671f0f",
   "metadata": {},
   "source": [
    "#### Plan\n",
    "\n",
    "- Explore the existence of more than one type of relationship between two actors through computing multiplexity.\n",
    "- Explore the tendency for actors to have more ties with other actors that are close geographically with propinquity.\n",
    "- Determine positional advantages/disadvantages of individuals from structural holes. This will help to think abut how and why the ways that an actor is connected affect its constraints and opportunities.\n",
    "- Understand which actors/directors/writers are the most important in the flow of the network, by computing betweenness/closeness/degree centrality.\n",
    "- Compute to which degree actors/directors/writers tend to cluster together, computing the clustering coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86238433",
   "metadata": {},
   "source": [
    "### Step 6: Build website and redact datastory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69003e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
